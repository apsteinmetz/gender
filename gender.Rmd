---
title: "Gender Diversity in R vs Python"
output: html_notebook
---

Over the last few years I have really enjoyed becoming part of the R community.  One of the best things about the community is the welcoming, inclusive and supportive nature of it.  I can't speak for other communities in the computer or data science worlds but I am well aware of the "brogrammer" culture that can be off-putting at times. The rise of codes of conduct across the open source world is changing things for the better, I think.

A couple months ago the creator of Python was interviewed saying [he thinks open source programming languages have a gender diversity problem](https://qz.com/1624252/pythons-creator-thinks-it-has-a-diversity-problem/).  This got me to thinking about whether the inclusive environment I observe in the R community is reflected in female contributions to popular packages and how it compares to the Python world.

We will take a multi-stage approach to getting some answers to this question.

1. Get the names of the top packages in R and Python.
2. Identify those packages which are maintained on Github.
3. Get the contributors to those packages (not as easy as it sounds).
4. 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(purrr)
library(jsonlite)
library(rvest)
library(installr)
library(data.table) #for downloading CRAN/RStudio logs
library(httr)
library(gh)
library(formattable)

source(file="download_RStudio_CRAN_data.R") 
```

Use the cranlogs api from RStudio to get top package downloads from their CRAN mirror.

```{r get_top_R_packages}
# ----------------------------------------------------------------
#select 5 random days from the last six months
# Read data from RStudio site
if (!file.exists("data/r_pkg_list.rdata")) {
  RStudio_CRAN_dir <- download_RStudio_CRAN_data(START = Sys.Date()-180,END = Sys.Date(),sample=5)
  # read .gz compressed files form local directory
  RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
  
  dim(RStudio_CRAN_data)
  
  # Find the most downloaded packages
  r_pkg_list <- most_downloaded_packages(RStudio_CRAN_data,n=100) %>% 
    as_tibble(.name_repair = make.names,c("downloads")) %>% 
    rename(package=X)
  
  save(r_pkg_list,file="data/r_pkg_list.rdata")
} else load("data/r_pkg_list.rdata")


```

Source for top 100 Python packages over the last year: https://hugovk.github.io/top-pypi-packages/
Get json (how helpful!).

```{r get_top_python_packages}
if (!file.exists("data/python_pkg_list.rdata")){
  
  py_pkgs_raw<-read_json("https://hugovk.github.io/top-pypi-packages/top-pypi-packages-365-days.json",
                         simplifyVector = TRUE)
  python_pkg_list <- py_pkgs_raw$rows[1:100,] %>% 
    as_tibble() %>% 
    rename(package=project,downloads=download_count)
  save(python_pkg_list,file="data/python_pkg_list.rdata")
} else load("data/python_pkg_list.rdata")

```

Build functions to get contributors to packages and then the real names of those contributors.
Search for relevant repo with just repo name, no user.

https://api.github.com/search/repositories?q=dplyr%20is:name+language:r&sort=stars&order=desc

will return:
      "full_name": "tidyverse/dplyr",

use that to get contributors:

Contributor url: https://api.github.com/repos/tidyverse/dplyr/contributors

will return all contributors with the JSON form:
   "url": "https://api.github.com/users/romainfrancois",

and that will return:
   "name": "Romain François",


```{r get_package_contributors}
library(dplyr)
library(jsonlite)

#this would actually be a list of multiple repos
repo_name <- "Rcpp"
language <- "r"

my_gh <- function(end_point) {
    return(jsonlite::fromJSON(jsonlite::toJSON(gh::gh(end_point)),simplifyVector = T))
}

json_to_df <- function(json){
    return(jsonlite::fromJSON(jsonlite::toJSON(json),simplifyVector = T))
}

# --------------------------------------------------------------------
get_contributor_ids <- function(target_repo){
# loop through all pages of contributors  
  search_url <- paste0("/repos/",
                       target_repo,
                       "/contributors")
  contributors_json <- gh(search_url)
  
  # return null in case of no contributors
  if (nchar(contributors_json[1])==0) return(NULL)
  
  contrib_node <- contributors_json
  repeat {
    contrib_node <- try(gh_next(contrib_node),silent=TRUE)
    if (is(contrib_node) == "try-error") break
    contributors_json <- c(contributors_json,contrib_node)  
  }

  contributor_ids <- json_to_df(contributors_json) %>%
    bind_rows() %>%   
    select(login,url,avatar_url)
  return(contributor_ids)
}

# ---------------------------------------------------------------------------
  get_name <- function(contrib_url){
    user_data <- my_gh(contrib_url)
    # just return login name if real name is missing
    if (is_empty(user_data$name)) return(user_data$login) else return(user_data$name)
  }

# --------------------------------------------------------------------
get_contrib_info <- function(repo_name="dplyr",language="r"){
  print(repo_name)
  # we don't know the github username associated with the package to construct a search
  # to get the most likely candidate
  search_url <- paste0("/search/repositories?q=",
                       repo_name
                      , "+language:", language
                      ,  "+is:name"
#                     ,"&sort=stars",
#                     ,   "&order=desc"
  )
  
  
  # first api call.  would need to would need to loop/map/apply over 
  # multiple contributors repo names
  repos <- my_gh(search_url) %>% .$items
  # return NULL if no repos in github are found
  if (length(repos) == 0) return(NULL)
  
  # get full path for exact match on repo name
  # there might be more than one user with repo of the same name
  # Since they will be in order of github "score", take just the first one
  target_repo <- repos %>% 
    select(name,full_name) %>% 
    filter(name == repo_name) %>%
    pull(full_name) %>% 
    .[1] %>% 
    unlist()
  # return NULL if no repos in github are found
  if (is.null(target_repo)) return(NULL)
  
  #second api call
  # get user urls for all contributors
  contributor_ids <- get_contributor_ids(target_repo)
  
  # return null in case of no contributors
  if (is.null(contributor_ids)) return(NULL)
  
  contrib_names<-map(contributor_ids$url,get_name) %>% unlist()
  print(paste(length(contrib_names)," contributors"))
  contrib_info <- tibble(language=language,
                         package=repo_name,
                         path=target_repo,
                         contributor=contrib_names) %>% 
    bind_cols(contributor_ids) %>% 
    select(-url) %>% unnest()
  return(contrib_info)
}
```


```{r}
load("data/r_pkg_list.rdata")
# Rcpp package is not categorized as R langauge so I got it manually.
r_pkg_list <- r_pkg_list %>% filter(package != "Rcpp")
if (!file.exists("data/r_pkg_contributors.rdata")){
  r_pkg_contributors <- NULL
# use loop so we can save intermediate steps
  for(pkg in r_pkg_list$package) {
    r_pkg_contributors <- r_pkg_contributors %>% 
      bind_rows(get_contrib_info(pkg,language="r"))
    save(r_pkg_contributors,file="data/r_pkg_contributors.rdata")
  }
} else load("data/r_pkg_contributors.rdata")

load("data/python_pkg_list.rdata")
if (!file.exists("data/python_pkg_contributors.rdata")){
  python_pkg_contributors <- NULL
  for(pkg in python_pkg_list$package) {
    python_pkg_contributors <- python_pkg_contributors %>% 
      bind_rows(get_contrib_info(pkg,language="python"))
    save(python_pkg_contributors,file="data/python_pkg_contributors.rdata")
  }  
} else load("data/r_pkg_contributors.rdata")
```
#Analysis
Now that we have the package contributor database. Do some analysis.

```{r}
load("data/r_pkg_contributors.rdata")

#summarize what we found
r_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  summary()
```

There are 73 out of the top 100 R packages with repos on Github.  The average number of contributors is 30. 300 people have contributed to the `fs` package, which is implements the linux file library `libuv`.

View the distribution of contributor count.
```{r}
r_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  ggplot(aes(as_factor(package),contributors)) + geom_col()+ coord_flip()
```




Who are the most prolific contributors among the top packages.  We note that many of the top packages are part of the tidyverse ecosystem and will have a very high degree of overlap among package contributors.  No one tidyverse package acts as a proxy for the rest, however.
```{r}
r_pkg_contributors %>% 
  group_by(contributor) %>% 
  summarise(packages=n()) %>% 
  arrange(desc(packages))

```

```{r}
load("data/python_pkg_contributors.rdata")

#summarize what we found
python_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  summary()
```
```{r}
python_pkg_contributors %>% 
  group_by(contributor) %>% 
  summarise(packages=n()) %>% 
  arrange(desc(packages))
```

```{r}
python_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  ggplot(aes(as_factor(package),contributors)) + geom_col()+ coord_flip()
```

Looking at the number of contributors for the top packages in both languages, we find that Python packages tend to have many more contributors.
```{r}
n_p <-python_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  mutate(language="Python") %>% 
  rownames_to_column() %>% 
  select(-package)

n_r <- r_pkg_contributors %>% 
  group_by(package) %>% 
  summarise(contributors=n()) %>% 
  arrange(desc(contributors)) %>% 
  rownames_to_column() %>% 
  mutate(language="R") %>% 
  select(-package)

contribs <- full_join(n_p,n_r) %>% mutate(rowname = as_factor(rowname))

contribs   %>% 
  ggplot(aes(rowname,contributors,group=language,color=language)) + 
  geom_line(size=2) + 
  theme(axis.text.x=element_blank()) +
  labs(main="Top Python Packages Show More Collaboration",
       x="Packages in Order of Contributors",
       y="Number of Contributors")
```


Who has contributed to both top R and Python packages?  Grouping by login name ensures that we don't get two different people with the same name.  There are 44 people who have contributed to some of both the top Python and R packages.
```{r}
c_p <- python_pkg_contributors %>% 
  group_by(login,contributor) %>% 
  summarise(python_packages=n())

c_r <- r_pkg_contributors %>% 
  group_by(login,contributor) %>% 
  summarise(r_packages=n())

inner_join(c_r,c_p,by=c("contributor","login")) %>% 
  arrange(desc(r_packages))
```

# Try to Determine Gender of Contributors

We use the Social Security baby names database for 1990.  It is important to be aware of the limitations of this.

1. I used 1990 because I guess that is close to the average birth year of most package contributors.  Is it?

2. The dataset contains registered births for only the United States.  Many contributors were born, or live today, outside the U.S. The U.S, while more of a melting pot than many countries, will have a subset of global names.

3. Transliteration of names from languages that don't use Western characters don't follow hard and fast rules. The same name might be transliterated multiple ways. "Sergey" or "Sergei?"

4. Ordering of surname and given name.  Chinese names typically are reported surname first.  Many Chinese people follow western conventions in global settings but maybe not.  I may be tagging the surname as the given name in some (many?) cases.

5. Many names are used for "both" (yes, I know) genders.  I choose an aribitrary ratio of gender predominance of 75% to pronounce certainty.  Noteworthy: "Hadley" is in our "Uncertain" bucket.

6. Gender identity becomes a choice at some age.  People may choose (or not choose) a gender  inconsistant with the identification in this dataset.

7. Some people use pseudonyms that are not common names.

Knowing all that, let's plunge on.

```{r}
load("data/names_90.rdata")
names_90 <- names_90 %>% 
  rename(first = Name) %>%
  mutate(first = tolower(first)) %>% 
  select(first,Gender,Count) %>% 
  spread(Gender,Count) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>% 
  mutate(prob_female=F/(F+M))

cutoff = 0.75 # threshhold probability for calling gender
names_90 <- names_90 %>% mutate(gender="Uncertain")
names_90 <- names_90 %>% mutate(gender=if_else(prob_female>cutoff,"Female",gender))
names_90 <- names_90 %>% mutate(gender=if_else(prob_female<(1-cutoff),"Male",gender))
names_90_subset <- names_90 %>% select(first,gender)
```

Now let's join the baby names to our contributors.
```{r}
r_pkg_contributors <-r_pkg_contributors %>%
  separate("contributor",into=c("first"),remove=FALSE,extra="drop")

python_pkg_contributors <-python_pkg_contributors %>%
  separate("contributor",into=c("first"),remove=FALSE,extra="drop")

r_genders <- r_pkg_contributors %>% 
  select(-path,-avatar_url,-login) %>% 
  mutate(first = tolower(first)) %>% 
  left_join(names_90_subset) %>% 
  mutate_all(~replace(., is.na(.),"Uncertain")) 

python_genders <- python_pkg_contributors %>% 
  select(-path,-avatar_url,-login) %>% 
  mutate(first = tolower(first)) %>% 
  left_join(names_90_subset) %>% 
  mutate_all(~replace(., is.na(.),"Uncertain")) 

```

```{r}
agg_gender <- bind_rows(python_genders,r_genders) %>% 
  select(language,gender) %>% 
  table() 
agg_gender %>% plot(main="Gender Representation in Package Contributions")
```
For our ultimate conclusion, let's assume that the "Uncertain" gender breaks into male and female in the same proportions that already exist.
```{r}
agg_gender <- bind_rows(python_genders,r_genders) %>% 
  filter(gender != "Uncertain") %>% 
  select(language,gender) %>% 
  table() %>% prop.table(margin=1) 

percent(agg_gender,digits = 0)
```
There it is.  This was certainly a lot of work to get to a four cell crosstab but we have our answer. Women contribute to the top R packages at more than twice the rate of top Python packages.  Can we speculate as to a reason?  R is almost exclusively a data sciencej language and most of the top packages reflect that. Python is more of a general purpose language that is also quite popular for data science, but as we look down the list of most popular python packages we see more utility packages.  Perhaps women are less represented in general computer science than they are in data science. With both languages, more than 90% of the contributors are men.  Clearly, we have a way to go with gender diversity in both communities.  Narrowing down the package list to focus on just data science packages is an avenue for further exploration.

There are other dimensions of diversity we might look at that are beyond the ability to infer from names.  It would be nice if we could see actual images of all contributors so we might make some observations about racial diversity or remove some of the amiguities around gender identification.  This approach would come with its own set of challenges and risks, however.

As mentioned at the start of this ariticle there are many reasons to take our conclusions with a grain of salt but the broad results conform with what we might intuitively expect.
