---
title: "Gender Diversity in R vs Python"
output: html_notebook
---

Guidance on gender of Chinese names: http://blog.tutorming.com/mandarin-chinese-learning-tips/difference-chinese-male-and-female-names-gender

```{r}
library(tidyverse)
library(purrr)
library(jsonlite)
library(rvest)
library(installr)
library(data.table) #for downloading CRAN/RStudio logs
library(httr)
library(gh)

source(file="download_RStudio_CRAN_data.R") 
```

Use the cranlogs api from RStudio to get top package downloads from their CRAN mirror.

```{r get_top_R_packages}
# ----------------------------------------------------------------
#select 5 random days from the last six months
# Read data from RStudio site
if (!file.exists("data/r_pkg_list.rdata")) {
  RStudio_CRAN_dir <- download_RStudio_CRAN_data(START = Sys.Date()-180,END = Sys.Date(),sample=5)
  # read .gz compressed files form local directory
  RStudio_CRAN_data <- read_RStudio_CRAN_data(RStudio_CRAN_dir)
  
  dim(RStudio_CRAN_data)
  
  # Find the most downloaded packages
  r_pkg_list <- most_downloaded_packages(RStudio_CRAN_data,n=100) %>% 
    as_tibble(.name_repair = make.names,c("downloads")) %>% 
    rename(package=X)
  
  save(r_pkg_list,file="data/r_pkg_list.rdata")
} else load("data/r_pkg_list.rdata")


```

Source for top 100 Python packages over the last year: https://hugovk.github.io/top-pypi-packages/
Get json (how helpful!).

```{r get_top_python_packages}
if (!file.exists("data/python_pkg_list.rdata")){
  
  py_pkgs_raw<-read_json("https://hugovk.github.io/top-pypi-packages/top-pypi-packages-365-days.json",
                         simplifyVector = TRUE)
  python_pkg_list <- py_pkgs_raw$rows[1:100,] %>% 
    as_tibble() %>% 
    rename(package=project,downloads=download_count)
  save(python_pkg_list,file="data/python_pkg_list.rdata")
} else load("data/python_pkg_list.rdata")

```

Build functions to get contributors to packages and then the real names of those contributors.
Search for relevant repo with just repo name, no user.

https://api.github.com/search/repositories?q=dplyr%20is:name+language:r&sort=stars&order=desc

will return:
      "full_name": "tidyverse/dplyr",

use that to get contributors:

Contributor url: https://api.github.com/repos/tidyverse/dplyr/contributors

will return all contributors with the JSON form:
   "url": "https://api.github.com/users/romainfrancois",

and that will return:
   "name": "Romain François",


```{r get_package_contributors}
library(dplyr)
library(jsonlite)

#this would actually be a list of multiple repos
repo_name <- "Rcpp"
language <- "r"

my_gh <- function(end_point) {
    return(jsonlite::fromJSON(jsonlite::toJSON(gh::gh(end_point)),simplifyVector = T))
}

json_to_df <- function(json){
    return(jsonlite::fromJSON(jsonlite::toJSON(json),simplifyVector = T))
}

# --------------------------------------------------------------------
get_contributor_ids <- function(target_repo){
# loop through all pages of contributors  
  search_url <- paste0("/repos/",
                       target_repo,
                       "/contributors")
  contributors_json <- gh(search_url)
  contrib_node <- contributors_json
  repeat {
    contrib_node <- try(gh_next(contrib_node),silent=TRUE)
    if (is(contrib_node) == "try-error") break
    contributors_json <- c(contributors_json,contrib_node)  
  }

  contributors <- json_to_df(contributors_json) %>%
    bind_rows() %>%   
    select(login,url,avatar_url)
  return(contributors)
}

# --------------------------------------------------------------------
get_contrib_info <- function(repo_name="dplyr",language="r"){
  print(repo_name)
  # we don't know the github username associated with the package to construct a search
  # to get the most likely candidate
  search_url <- paste0("/search/repositories?q=",
                       repo_name
 #                    ,  "+is:name"
#                      , "+language:", language
#                     ,"&sort=stars",
#                     ,   "&order=desc"
  )
  
  
  # first api call.  would need to would need to loop/map/apply over 
  # multiple contributors repo names
  all_repos <- my_gh(search_url) %>% .$items %>% .$full_name %>% unlist()
  
  # get full path for exact match on repo name
  regex_str <- paste0(".+/",repo_name,"$")
  target_repo <- all_repos[str_detect(all_repos,regex_str)][1]
  # no error checking if repo is not found
  print(target_repo)
  
  # there might be more than one user with repo of the same name
  # Since they will be in order of github "score", take just the first one
  #second api call
  contributor_ids <- get_contributor_ids(target_repo)
    
  #third api call. would need to loop/map/apply over multiple contributors
  # need to strip base url
  get_name <- function(contrib_url){
    user_data <- my_gh(contrib_url)
    # just return login name if real name is missing
    if (is_empty(user_data$name)) return(user_data$login) else return(user_data$name)
  }
  
  contrib_names<-map(contributor_ids$url,get_name) %>% unlist()
  
  print(paste(length(contrib_names)," contributors"))
  
  contrib_info <- tibble(language=language,
                         package=repo_name,
                         path=target_repo,
                         contributor=contrib_names) %>% 
    bind_cols(contributors) %>% 
    select(-url)
  
  
  return(contrib_info)
}
```


```{r}
load("data/r_pkg_list.rdata")
load("data/python_pkg_list.rdata")

dummy<- function(repo_name,language){
  return(tibble(package=repo_name,language=language,stuff=1:3))
}
dat <- map(r_pkg_list$package,get_contrib_info,language="r") %>% bind_rows()
```

